{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') # torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(73512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dane syntetyczne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(0, 50, 0.02)\n",
    "synthetic_data = (np.sin(indices * 3) + indices / 10 + (indices / 10) ** 2 + np.sin(indices * 10)) #/ np.exp(indices / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20, 10])\n",
    "plt.plot(synthetic_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = synthetic_data.min()\n",
    "max_value = synthetic_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_seq = []\n",
    "data_targets = []\n",
    "sequence_len = 150\n",
    "for i in range(len(synthetic_data) - sequence_len - 1):\n",
    "    data_seq.append(torch.from_numpy(synthetic_data[i:i + sequence_len]))\n",
    "    data_targets.append(synthetic_data[i + sequence_len + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (torch.stack(data_seq).float() - min_value) / max_value\n",
    "data_targets = (torch.Tensor(data_targets).float() - min_value) / max_value\n",
    "train_indices = rng.random(len(data_seq)) > 0.3\n",
    "test_indices = ~train_indices\n",
    "train_set = torch.utils.data.TensorDataset(data[train_indices], data_targets[train_indices])\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_data, test_targets = data[test_indices], data_targets[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(num_hidden, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "model = SimpleRegressor(sequence_len, 5, 1).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fun = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train() \n",
    "\n",
    "# Training loop\n",
    "for epoch in range(101):\n",
    "    for x, targets in train_loader:\n",
    "        x = x.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        preds = model(x)\n",
    "        preds = preds.squeeze(dim=1) \n",
    "        \n",
    "        optimizer.zero_grad() \n",
    "        loss = loss_fun(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_preds = model(test_data.to(device))\n",
    "    print(torch.abs(test_preds.squeeze()-test_targets.to(device)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 5])\n",
    "plt.plot(test_targets.numpy(), label='original')\n",
    "plt.plot(test_preds.cpu().numpy(), label='predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Koniec laborki?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co poszło nie tak?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(len(data) * 0.7)\n",
    "train_set = torch.utils.data.TensorDataset(data[:train_split], data_targets[:train_split])\n",
    "train_loader = DataLoader(train_set, batch_size=32, drop_last=True)\n",
    "test_data, test_targets = data[train_split:], data_targets[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRegressor(sequence_len, 5, 1).to(device)\n",
    "model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fun = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(101):\n",
    "    for x, targets in train_loader:\n",
    "        x = x.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        preds = model(x)\n",
    "        preds = preds.squeeze(dim=1) \n",
    "        \n",
    "        optimizer.zero_grad() \n",
    "        loss = loss_fun(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_preds = model(test_data.to(device))\n",
    "    print(torch.abs(test_preds.squeeze() - test_targets.to(device)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 5])\n",
    "plt.plot(test_targets.numpy(), label='original')\n",
    "plt.plot(test_preds.cpu().numpy(), label='predictions_short_term')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sieć rekurencyjna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs, num_state):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(num_inputs + num_state, num_hidden)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        self.linear_out = nn.Linear(num_hidden, num_outputs)\n",
    "        self.linear_state = nn.Linear(num_hidden, num_state)\n",
    "\n",
    "    def forward(self, x, state):\n",
    "        x = torch.cat([x, state], 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act_fn(x)\n",
    "        out = self.linear_out(x)\n",
    "        state = self.linear_state(x)\n",
    "        return out, state\n",
    "    \n",
    "model = RecurrentRegressor(1, 5, 1, 5).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dokończ pętlę uczącą poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fun = nn.MSELoss()\n",
    "\n",
    "for epoch in range(101):\n",
    "    for x, targets in train_loader:\n",
    "        x = x.to(device)\n",
    "        targets = targets.to(device)\n",
    "        loss_total = 0\n",
    "        state = torch.zeros(len(x), 5).to(device)\n",
    "        optimizer.zero_grad() \n",
    "        for i in range(x.size(1)):\n",
    "            ### Co tutaj?\n",
    "        loss_total.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    state = torch.zeros(len(test_data), 5).to(device)\n",
    "    test_preds = []\n",
    "    for i in range(test_data.size(1)):\n",
    "        x_one = test_data[:, i].unsqueeze(1).to(device)\n",
    "        preds, state = model(x_one, state)\n",
    "    test_preds.append(preds)\n",
    "    print(torch.abs((torch.cat(test_preds).squeeze() - test_targets.to(device))).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 5])\n",
    "plt.plot(test_targets, label='original')\n",
    "plt.plot(torch.cat(test_preds).squeeze().cpu().numpy(), label='predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sieci rekurencyjne w Torchu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "input_size = 3\n",
    "hidden_size = 4\n",
    "num_layers = 2\n",
    "rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=2, batch_first=False) #batch_first=False is default!!\n",
    "rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    sequence_len = 5\n",
    "    x = torch.randn(sequence_len, batch_size, input_size)\n",
    "    h0 = torch.randn(num_layers, batch_size, hidden_size)\n",
    "    output, hn = rnn(x, h0)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, out_size):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, out_size)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        all_outputs, hidden = self.rnn(x, hidden)\n",
    "        out = all_outputs[-1] # We are interested only in the last output\n",
    "        x = self.fc(out)\n",
    "        return x, hidden\n",
    "    \n",
    "model = RNNRegressor(1, 5, 2, 1).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fun = nn.MSELoss()\n",
    "\n",
    "for epoch in range(101):\n",
    "    for x, targets in train_loader:\n",
    "        x = x.to(device).unsqueeze(2)\n",
    "        targets = targets.to(device)\n",
    "        hidden = model.init_hidden(x.size(0)).to(device)\n",
    "        preds, last_hidden = model(x, hidden)\n",
    "        preds = preds.squeeze(1)\n",
    "        optimizer.zero_grad() \n",
    "        loss = loss_fun(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    hidden = model.init_hidden(len(test_data)).to(device)\n",
    "    test_preds, _ = model(test_data.to(device).unsqueeze(2),hidden)\n",
    "    print(torch.abs(test_preds.squeeze() - test_targets.to(device)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 5])\n",
    "plt.plot(test_targets, label='original')\n",
    "plt.plot(test_preds.squeeze().cpu().numpy(), label='predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Czy możemy jakoś rozdzielić krótką i długą pamięć?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LSTM](https://cdn-images-1.medium.com/max/1000/1*Ht2-sUJHi65wDwnR276k3A.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 5\n",
    "num_layers = 1\n",
    "batch_size = 3\n",
    "hidden_size = 2\n",
    "lstm = nn.LSTM(input_size=1, hidden_size=hidden_size, num_layers=num_layers)\n",
    "lstm_input = torch.randn(sequence_length, batch_size, 1)\n",
    "hidden_0 = torch.randn(num_layers, batch_size, hidden_size)\n",
    "cell_state_0 = torch.randn(num_layers, batch_size, hidden_size)\n",
    "output, (hn, cn) = lstm(lstm_input, (hidden_0, cell_state_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.size())\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hn)\n",
    "print(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, out_size):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, out_size)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        state = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden, state\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        all_outputs, hidden = self.lstm(x, hidden)\n",
    "        out = all_outputs[-1] # We are interested only in the last output\n",
    "        x = self.fc(out)\n",
    "        return x, hidden\n",
    "    \n",
    "model = LSTMRegressor(1, 20, 2, 1).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fun = nn.MSELoss()\n",
    "\n",
    "for epoch in range(101):\n",
    "    for x, targets in train_loader:\n",
    "        x = x.to(device).unsqueeze(2)\n",
    "        targets = targets.to(device)\n",
    "        hidden, state = model.init_hidden(x.size(0))\n",
    "        hidden, state = hidden.to(device), state.to(device) \n",
    "        preds, last_hidden = model(x, (hidden,state))\n",
    "        preds = preds.squeeze(1)\n",
    "        optimizer.zero_grad() \n",
    "        loss = loss_fun(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    hidden, state = model.init_hidden(test_data.size(0))\n",
    "    hidden, state = hidden.to(device), state.to(device) \n",
    "    test_preds, _ = model(test_data.to(device).unsqueeze(2), (hidden, state))\n",
    "    print(torch.abs(test_preds.squeeze() - test_targets.to(device)).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 5])\n",
    "plt.plot(test_targets, label='original')\n",
    "plt.plot(test_preds.squeeze().cpu().numpy(), label='predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini zadanie: Jak wyglądałyby predykcje w oparciu o poprzednie predykcje?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predykcja Sequence to sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price = pd.read_csv(\"https://www.galera.ii.pw.edu.pl/~kdeja/data/all_stocks_5yr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mastercard_stock = stock_price[stock_price.Name==\"MA\"].open.values\n",
    "visa_stock = stock_price[stock_price.Name==\"V\"].open.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 5])\n",
    "plt.plot(mastercard_stock, label='mastercard')\n",
    "plt.plot(visa_stock, label='visa')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_min_value = mastercard_stock.min()\n",
    "m_max_value = mastercard_stock.max()\n",
    "v_min_value = visa_stock.min()\n",
    "v_max_value = visa_stock.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_seq = []\n",
    "data_targets = []\n",
    "sequence_len = 50\n",
    "for i in range(len(mastercard_stock) - sequence_len):\n",
    "    data_seq.append(torch.from_numpy(mastercard_stock[i:i + sequence_len]))\n",
    "    data_targets.append(torch.from_numpy(visa_stock[i:i + sequence_len]))\n",
    "    \n",
    "data = (torch.stack(data_seq).float() - m_min_value) / m_max_value\n",
    "data_targets = (torch.stack(data_targets).float() - v_min_value) / v_max_value    \n",
    "\n",
    "train_split = int(len(data) * 0.7)\n",
    "train_set = torch.utils.data.TensorDataset(data[:train_split], data_targets[:train_split])\n",
    "train_loader = DataLoader(train_set, batch_size=32, drop_last=True)\n",
    "train_set = torch.utils.data.TensorDataset(data[:train_split], data_targets[:train_split])\n",
    "train_loader = DataLoader(train_set, batch_size=32, drop_last=True)\n",
    "test_data, test_targets = data[train_split:], data_targets[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 5\n",
    "num_layers = 1\n",
    "batch_size = 3\n",
    "hidden_size = 2\n",
    "projection_size = 1\n",
    "\n",
    "lstm = nn.LSTM(input_size=1, hidden_size=hidden_size, num_layers=num_layers, proj_size=projection_size)\n",
    "lstm_input = torch.randn(sequence_length, batch_size, 1)\n",
    "hidden_0 = torch.randn(num_layers, batch_size, projection_size)\n",
    "cell_state_0 = torch.randn(num_layers, batch_size, hidden_size)\n",
    "output, (hn, cn) = lstm(lstm_input, (hidden_0, cell_state_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Seq_Regressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, out_size):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.proj_size = out_size\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, proj_size=out_size)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.proj_size)\n",
    "        state = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden, state\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        x = torch.transpose(x,0,1)\n",
    "        all_outputs, hidden = self.lstm(x, hidden)\n",
    "        all_outputs = torch.transpose(all_outputs,0,1)\n",
    "        return all_outputs, hidden\n",
    "    \n",
    "model = LSTM_Seq_Regressor(1, 50, 2, 1).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fun = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(101):\n",
    "    for x, targets in train_loader:\n",
    "        x = x.to(device).unsqueeze(2)\n",
    "        targets = targets.to(device)\n",
    "        hidden, state = model.init_hidden(x.size(0))\n",
    "        hidden, state = hidden.to(device), state.to(device) \n",
    "        preds, last_hidden = model(x, (hidden,state))\n",
    "        preds = preds.squeeze(2)\n",
    "        optimizer.zero_grad() \n",
    "        loss = loss_fun(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    selected_test_targets = []\n",
    "    preds = []\n",
    "    for i in range(0, len(test_targets), sequence_len):\n",
    "        hidden, state = model.init_hidden(1)\n",
    "        hidden, state = hidden.to(device), state.to(device) \n",
    "        selected_test_targets.append(test_targets[i])\n",
    "        pred, _ = model(test_data[i].to(device).unsqueeze(0).unsqueeze(2), (hidden, state))\n",
    "        preds.append(pred.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 5])\n",
    "plt.plot(torch.cat(selected_test_targets).cpu().numpy(), label='original')\n",
    "plt.plot(torch.cat(preds).cpu().numpy(), label='predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co się stało, skąd takie dziwne predykcje?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasyfikacja serii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libras = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/libras/movement_libras.data\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libras.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = libras[90].values\n",
    "data = libras.values[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.from_numpy(data).float()\n",
    "data_targets = torch.from_numpy(classes).long()\n",
    "\n",
    "train_indices = rng.random(len(data)) > 0.3\n",
    "test_indices = ~train_indices\n",
    "train_set = torch.utils.data.TensorDataset(data[train_indices], data_targets[train_indices])\n",
    "train_loader = DataLoader(train_set, batch_size=32)\n",
    "test_data, test_targets = data[test_indices], data_targets[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Napisz klasyfikator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dane o różnej długości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class VariableLenDataset(Dataset):\n",
    "    def __init__(self, in_data, target):\n",
    "        self.data = [(x, y) for x, y in zip(in_data, target)]      \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        in_data, target = self.data[idx]\n",
    "        return in_data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_gen_val = 10\n",
    "max_gen_val = 1001\n",
    "samples = 1000\n",
    "max_gen_len = 32\n",
    "\n",
    "data = []\n",
    "targets = []\n",
    "max_val = -1\n",
    "for _ in range(samples):\n",
    "    seq_len = rng.integers(low=1, high=max_gen_len, size=1)\n",
    "    data_in = rng.integers(low=min_gen_val, high=max_gen_val, size=seq_len)\n",
    "    data_sum = np.array([data_in[:i + 1].sum() for i in range(len(data_in))])\n",
    "    data.append(torch.from_numpy(data_in))\n",
    "    targets.append(torch.from_numpy(data_sum))\n",
    "    max_val = data_sum[-1] if data_sum[-1] > max_val else max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = int(len(data) * 0.7)\n",
    "data = [(x / max_val).float() for x in data]\n",
    "targets = [(x / max_val).float() for x in targets]\n",
    "train_set = VariableLenDataset(data[:train_indices], targets[:train_indices])\n",
    "test_set = VariableLenDataset(data[train_indices:], targets[train_indices:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "pad = 0\n",
    "\n",
    "def pad_collate(batch, pad_value=pad):\n",
    "    xx, yy = zip(*batch)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    y_lens = [len(y) for y in yy]\n",
    "\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
    "    yy_pad = pad_sequence(yy, batch_first=True, padding_value=pad_value)\n",
    "\n",
    "    return xx_pad, yy_pad, x_lens, y_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=50, shuffle=True, collate_fn=pad_collate)\n",
    "test_loader = DataLoader(test_set, batch_size=50, shuffle=False, drop_last=False, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(train_set[0][0]))\n",
    "print(len(train_set[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Seq_Regressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, out_size):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.proj_size = out_size\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, proj_size = out_size)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.proj_size)\n",
    "        state = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden, state\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        # x = torch.transpose(x, 0, 1)\n",
    "        all_outputs, hidden = self.lstm(x, hidden)\n",
    "        # all_outputs = torch.transpose(all_outputs, 0, 1)\n",
    "        return all_outputs, hidden\n",
    "    \n",
    "model = LSTM_Seq_Regressor(1, 200, 1, 1).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fun = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(101):\n",
    "    for x, targets, x_len, target_len in train_loader:\n",
    "        x = x.to(device).unsqueeze(2)\n",
    "        targets = targets.to(device)\n",
    "        hidden, state = model.init_hidden(x.size(0))\n",
    "        hidden, state = hidden.to(device), state.to(device) \n",
    "        \n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        preds, _ = model(x, (hidden, state))\n",
    "        preds = torch.transpose(preds, 0, 1)\n",
    "        \n",
    "#         x_packed = pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n",
    "#         preds_packed, _ = model(x_packed, (hidden, state))\n",
    "#         preds, pred_len = pad_packed_sequence(preds_packed, batch_first=True, padding_value=pad)\n",
    "        \n",
    "        preds = preds.squeeze(2)\n",
    "        optimizer.zero_grad()\n",
    "        mask = targets != pad\n",
    "        loss = loss_fun(preds[mask], targets[mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for x, targets, x_len, target_len in test_loader:\n",
    "        x = x.to(device).unsqueeze(2)\n",
    "        targets = targets.to(device)\n",
    "        hidden, state = model.init_hidden(x.shape[0])\n",
    "        hidden, state = hidden.to(device), state.to(device)\n",
    "\n",
    "        x = torch.transpose(x, 0, 1)        \n",
    "        preds, (last_hidden, last_state) = model(x, (hidden, state))\n",
    "        preds = torch.transpose(preds, 0, 1)\n",
    "        \n",
    "#         x_packed = pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n",
    "#         preds_packed, (last_hidden, last_state) = model(x_packed, (hidden, state))\n",
    "#         preds, pred_len = pad_packed_sequence(preds_packed, batch_first=True, padding_value=pad)\n",
    "        \n",
    "        preds = preds.squeeze(2)\n",
    "        mask_tgt = targets != pad\n",
    "        print(last_hidden)\n",
    "#         print(targets)\n",
    "#         print(preds)\n",
    "#         print(torch.abs(preds[mask_tgt] - targets[mask_tgt]).mean())\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packed Sequences - kiedy używać?\n",
    "Np. w przypadku, gdy dokonujemy klasyfikacji jakieś serii na podstawie OSTATNIEGO ukrytego stanu komórki LSTM (lub innych):\n",
    "\n",
    "`preds, (last_hidden, last_state) = model(x, (hidden, state))`\n",
    "\n",
    "W przypadku niewykorzystywania Packed Sequences, wartość \"last_hidden\" będzie zawierać wartość stanu ukrytego komórki LSTM po przetworzeniu ostatniego elementu każdej sekwencji w minipakiecie. Przy wykorzystaniu paddingu jest to niepożądane - ostatnie elementy padowanych sekwencji nie mają znaczenia! Wtedy odpowiednie wartości stanów ukrytych należy wyciągać ręcznie ze zmiennej \"preds\".\n",
    "\n",
    "Przy wykorzystaniu Packed Sequences, wartość \"last_hidden\" będzie zawierać wartość stanu ukrytego komórki LSTM po przetworzeniu ostatniego elementu sekwencji nie będącego paddingiem. Dzięki temu można ją bezpośrednio wykorzystać np. w warstwie gęstej do klasyfikacji, bęz wyciągania tych samych informacji ze zmiennej \"preds\". "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
